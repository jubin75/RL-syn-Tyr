# Discovery of Tyrosinase Inhibitors from AI De Novo Molecular Generation to Dual-Path Lead Optimization: The Competition between AI and Medicinal Chemists‌

This study proposes an innovative framework that integrates de novo molecular design with synthetic feasibility evaluation, leveraging RL-driven forward synthesis planning to significantly improve both the generation efficiency and synthetic success rate of target molecules. Initially, 200 high-affinity fragments were selected from a building block database based on molecular docking results to form the starting pool. In subsequent iterations, a diversity-constrained mechanism was introduced-fragments were selected based on structural fingerprint clustering and synthesis complexity weighting to ensure both novelty and coverage. During the molecule generation phase, Monte Carlo Tree Search (MCTS) was used to guide synthetic pathway exploration. The novelty of this framework lies in three key aspects: Bidirectional optimization: Simultaneous optimization of molecular bioactivity and synthetic accessibility; Adaptive exploration: Dynamic reward shaping based on fragment usage frequency to suppress repetitive generation of redundant structures.

Using compound AI10 as the reference molecule, an RL-driven molecular generation strategy to autonomously design target compounds were employed. Specifically, a fragment-based growth and expansion approach was applied, in which the reference molecule was decomposed into multiple query fragments. These fragments were then used to assemble sets of structurally related fragments, from which new molecules were generated by predefined reaction templates. The resulting candidates were evaluated by structural similarity and docking against the reference scaffold, enabling the algorithm to yield compounds with comparable architectures and physicochemical properties. By integrating predicted activity, drug-likeness, synthetic feasibility, and structural similarity to the lead compound AI10, 32 candidate molecules (AI10-a1 to AI10-a32) were prioritized for laboratory synthesis.

## Repo structure and module interfaces
This repo keeps a **shared root-level `data/` directory** and provides a small shared base module:

- `rlsyn_base/`: repo-root shared utilities (e.g. stable `data/` paths)
- `Ref_based_syn/`: reference-molecule-guided forward synthesis + RL (importable package)
- `RL_based_syn/`: separate RL module (kept distinct)

### How to run the reference-based inference demo
From repo root:

```bash
python -m Ref_based_syn.infer --validate
```

This runs a full validation pipeline with a built-in reference SMILES case and produces a ranked report under `./results/`.

## Installation (recommended)
This repo is organized as a **repo-root project** with `Ref_based_syn` as a Python package.

- **Create conda env** (example; adjust for your platform):

```bash
conda env create -f Ref_based_syn/environment.yaml
conda activate ref_syn
```

Notes:
- **RDKit** is required for fragment decomposition / reactions / similarity.
- **Docking** (optional) requires `openbabel` + `qvina02` + a receptor file. This repo stores the receptor under `test/2y9x/2y9x_pocket.pdb` and converts it to `.pdbqt` automatically when `obabel` is available.

## Quick validation: inference pipeline (details)
The validation script follows the reference-based workflow:
decompose reference → retrieve similar fragments/building blocks → generate by reaction templates →
evaluate similarity + (optional) docking → apply drug-likeness + synthetic feasibility filters → rank Top-K.

Run:

```bash
python -m Ref_based_syn.infer --validate
```

Outputs a JSON report under `./results/` (e.g. `ref_infer_validation_*.json`) containing:
- `meta`: reference SMILES, number of query fragments, number of templates, docking enabled or not
- `top_k`: ranked candidates with similarity/drug-like/synthesizable scores (and docking score when available)

## Training entry (original code)
If you want to train TD3 on the filtered reaction set (requires the prepared `data/*` files used by `SynthesisEnv`):

```bash
python -m Ref_based_syn.main --max_episodes 2
```

## Project wiring (repo-root base module)
`Ref_based_syn` uses the repo-root shared module `rlsyn_base` for **stable paths** (e.g. the shared `data/` directory).
This keeps `data/` at the repo root unchanged while allowing `Ref_based_syn` to be imported and executed reliably.

## Test assets (what reviewers should use)
- **AI10 reference SMILES**: `test/2y9x/compounds.smi` (the inference demo defaults to this file)
- **2y9x receptor pocket**: `test/2y9x/2y9x_pocket.pdb`

## Reviewer minimal reproducibility (hard checklist)
This is the **minimal runnable path** for reviewers after cloning.

### 1) Environment

```bash
conda env create -f Ref_based_syn/environment.yaml
conda activate ref_syn
```

### 2) Sanity-check test assets

```bash
ls -lh test/2y9x/compounds.smi test/2y9x/2y9x_pocket.pdb
```

### 3) Run the minimal end-to-end validation (no docking required)

```bash
python -m Ref_based_syn.infer --validate
```

Expected:
- exit code **0**
- a JSON report saved to `./results/ref_infer_validation_*.json`

### Optional: enable docking (best-effort)
Docking depends on `openbabel/obabel` and a working `qvina02` binary for your platform. If not available, the minimal validation above remains runnable and is the recommended review path.